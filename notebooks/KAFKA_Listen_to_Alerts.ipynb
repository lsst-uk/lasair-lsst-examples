{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7798e8",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"img/lasair.png\" alt=\"drawing\" width=\"50\"/>\n",
    "</p>\n",
    "<h1 align=\"center\">  Kafka Tutorial: </h1>\n",
    "<h2 align=\"center\">  Consuming Public Alerts </h2>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## What you'll learn\n",
    "\n",
    "This notebook will walk you through making your own code to consume alerts from Lasair filters. You will learn:\n",
    "\n",
    "* How to set up a kafka consumer with the `lasair` helper function\n",
    "* What stream options are available for the Lasair filters\n",
    "* How to navigate the data produced by these stream options. \n",
    "\n",
    "\n",
    "## Pre-requesites\n",
    "\n",
    "\n",
    "### **Have you installed the `lasair` client ?**\n",
    "\n",
    "You can do this through pip!\n",
    "\n",
    "```bash\n",
    "pip install lasair\n",
    "```\n",
    "\n",
    "### You also need the following python libraries:\n",
    "  - `json`\n",
    "  - `pandas`\n",
    "  - `matplotlib`\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<h2 align=\"center\">  1. Setting-up your first consumer </h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a382a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from lasair import LasairError, lasair_consumer\n",
    "import random # This only needed for the tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad02a62",
   "metadata": {},
   "source": [
    "### Config for the `lasair_consumer`\n",
    "\n",
    "To connect to a kafka stream you need a few things:\n",
    "* The socket (Host:Port) of the server (where is the server on the internet and how do I get into it?): `lasair-lsst-kafka_pub.lsst.ac.uk:9092`\n",
    "* The endpoint (where are do I send my requests on the server?): `https://api.lasair.lsst.ac.uk/api`\n",
    "* The topic (corresponding to your filter of choice):  `lasair_2Zooniverse\"`\n",
    "* The `group_id`, which keeps track of which alerts you've already seen and which ones you have yet to receive. \n",
    "* How many alerts (N) are we polling for?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a082d3b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f3bd9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#endpoint     = \"https://api.lasair.lsst.ac.uk/api\"\n",
    "endpoint     = \"https://api.lasair.lsst-dev.lsst.ac.uk/api\"\n",
    "#kafka_server = \"lasair-lsst-kafka_pub.lsst.ac.uk:9092\"\n",
    "kafka_server = \"lasair-lsst-dev-kafka_pub.lsst.ac.uk:9092\"\n",
    "#topic        = \"lasair_83lvra_feeder_full\"\n",
    "topic        = \"lasair_83lasair_tutorial_basic_stream\"\n",
    "group_id     = \"tutorial\"+str(int(random.random()*10000000000)) # CREATING RANDOM ID\n",
    "N            = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b75d902",
   "metadata": {},
   "source": [
    "Now let's use the Lasair client to make our consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c407e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = lasair_consumer(\n",
    "    kafka_server,    \n",
    "    group_id,        \n",
    "    topic            \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621e5a56",
   "metadata": {},
   "source": [
    "### Polling your first alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cd6eed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"diaObjectId\": 313928193916534808,\n",
      "  \"lastDiaSourceMjdTai\": 61069.08298840221,\n",
      "  \"latestR\": 0.983908,\n",
      "  \"nDiaSources\": 51,\n",
      "  \"ra\": 52.32789570550791,\n",
      "  \"decl\": -26.86992277816011,\n",
      "  \"separationArcsec\": 1.081\n",
      "}\n",
      "{\n",
      "  \"diaObjectId\": 314003013720080448,\n",
      "  \"lastDiaSourceMjdTai\": 61088.212443683144,\n",
      "  \"latestR\": 0.964177,\n",
      "  \"nDiaSources\": 18,\n",
      "  \"ra\": 150.1314100332278,\n",
      "  \"decl\": 2.4053689123972593,\n",
      "  \"separationArcsec\": 0.696,\n",
      "  \"UTC\": \"2026-02-17 05:13:10\"\n",
      "}\n",
      "{\n",
      "  \"diaObjectId\": 314051320824201308,\n",
      "  \"lastDiaSourceMjdTai\": 61088.09744609636,\n",
      "  \"latestR\": 0.953794,\n",
      "  \"nDiaSources\": 3,\n",
      "  \"ra\": 52.55095983903494,\n",
      "  \"decl\": -28.077585952842437,\n",
      "  \"separationArcsec\": 9.058,\n",
      "  \"UTC\": \"2026-02-17 05:13:10\"\n",
      "}\n",
      "You have reached the end of the queue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%4|1771582701.075|MAXPOLL|rdkafka#consumer-1| [thrd:main]: Application maximum poll interval (300000ms) exceeded by 252ms (adjust max.poll.interval.ms for long-running message processing): leaving group\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "while n < N: # whilst we have not read N messages\n",
    "    # ask the lasair consumer to poll the NEXT MESSAGE IN THE QUEUE\n",
    "    msg = consumer.poll(timeout=20)\n",
    "    \n",
    "    if msg is None:\n",
    "        # If that message is None, we have reached the end of the queue!\n",
    "        break\n",
    "\n",
    "    if msg.error():\n",
    "        # If there is an error we want to raise an exception\n",
    "        raise LasairError(\"Error while consuming message: {}\".format(msg.error()))\n",
    "        break\n",
    "\n",
    "    # If we have a message we need to read it into Json format\n",
    "    jmsg = json.loads(msg.value())\n",
    "\n",
    "    # Then we can write it out!\n",
    "    print(json.dumps(jmsg, indent=2))\n",
    "    n += 1\n",
    "print('You have reached the end of the queue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49252b96",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">  2. Saving the data with the correct format </h2>\n",
    "\n",
    "\n",
    "In a real life setting you won't be printing large dictionaries to your notebook or terminal, you want it in a `.json` file. \n",
    "\n",
    "Let's select an output directory for our data **NOTE: I set this tutorial up to point to the /tmp directory** the data will be cleared when you restart your system. Feel free to select a different location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb27b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir   = \"/tmp/lasair_consumer_output\" # this won't work on windows\n",
    "OUTPUT_PATH = Path(output_dir)\n",
    "OUTPUT_PATH.mkdir(exist_ok=True, parents=True) # If sub directory doesn't exist, create it. If it does exist, do nothing. If the parent directories don't exist, create them too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ddb715",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a78977b2",
   "metadata": {},
   "source": [
    "Since we have already listened to our alerts we have moved in the queue! If we want the same alerts we printed above, we need a new `group_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "149f0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id     = \"tutorial\"+str(int(random.random()*10000000000)) # CREATING RANDOM ID\n",
    "\n",
    "consumer = lasair_consumer(\n",
    "    kafka_server,    \n",
    "    group_id,        \n",
    "    topic            \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b849e9ac",
   "metadata": {},
   "source": [
    "Now we poll and we dump each message in a file which will have the structure:\n",
    "\n",
    "```\n",
    "[\n",
    "    {MESSAGE_ALERT1},\n",
    "    {MESSAGE_ALERT2},\n",
    "    ....\n",
    "    {MESSAGE_ALERTN},\n",
    "]\n",
    "```\n",
    "\n",
    "Each message contains fields and sub-dictionaries.\n",
    "\n",
    "Now our consumer **is a little more invovled** than it was above, because we need to make sure the brackets and commas are in the right place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a56fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "first = True\n",
    "# To ensure we don't leave out file open we work within a `with` scope\n",
    "with open(OUTPUT_PATH / f\"message_BASIC.tmp.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    # first we write the opening square bracket for the json list\n",
    "    f.write(\"[\\n\")\n",
    "    while n < N:\n",
    "        msg = consumer.poll(timeout=20)\n",
    "        if msg is None:\n",
    "            break\n",
    "        if msg.error():\n",
    "            raise LasairError(\"Error while consuming message: {}\".format(msg.error()))\n",
    "            break\n",
    "        # 2. If we make it here it means we have messages. \n",
    "        raw = msg.value()\n",
    "        # msg.value() may be bytes or str depending on client\n",
    "        if isinstance(raw, bytes):\n",
    "            raw = raw.decode(\"utf-8\")\n",
    "\n",
    "        # 3. Get the JSON data for our alert.\n",
    "        result = json.loads(raw)\n",
    "        \n",
    "        # write comma before each object after the first\n",
    "        if not first:\n",
    "            f.write(\",\\n\")\n",
    "        first = False\n",
    "        \n",
    "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "        n += 1\n",
    "    f.write(\"]\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff942ae3",
   "metadata": {},
   "source": [
    "Above we saved the data to a `.tmp.json` file which we will now rename. This practice is called \"saving files atomically\" and it's a way to not overwrite a good file with corrupted data. If the while loop above breaks halfway through we will be able to tell the good from the bad files. (For example Vim has Swap files for the same reason). \n",
    "\n",
    "\n",
    "Once we are happy everything has run properly we can replace our tmp file name with its final name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b48deba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the temporary files and rename them to .json\n",
    "import os\n",
    "\n",
    "\n",
    "os.replace(str(OUTPUT_PATH / f\"message_BASIC.tmp.json\"), str(OUTPUT_PATH / f\"message_BASIC.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35882907",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> 3. Reading a Basic Alert File </h2>\n",
    "\n",
    "I am going to show you how to handle these with pandas since it already has excellent JSON support. \n",
    "This tutorial will not give you a \"raw python\" solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "017f5bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de65f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d21dcf4f",
   "metadata": {},
   "source": [
    "Pandas already has a `read_json` function, which works quite well even for nested data structures (which we will need later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fde60802",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_json(OUTPUT_PATH/\"message_BASIC.json\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c43c6e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diaObjectId</th>\n",
       "      <th>lastDiaSourceMjdTai</th>\n",
       "      <th>latestR</th>\n",
       "      <th>nDiaSources</th>\n",
       "      <th>ra</th>\n",
       "      <th>decl</th>\n",
       "      <th>separationArcsec</th>\n",
       "      <th>UTC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313963356964782123</td>\n",
       "      <td>61069.082988</td>\n",
       "      <td>0.977299</td>\n",
       "      <td>2</td>\n",
       "      <td>52.822487</td>\n",
       "      <td>-27.574832</td>\n",
       "      <td>1.599</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>313871013231722745</td>\n",
       "      <td>61088.212444</td>\n",
       "      <td>0.936848</td>\n",
       "      <td>23</td>\n",
       "      <td>149.156940</td>\n",
       "      <td>0.772347</td>\n",
       "      <td>0.326</td>\n",
       "      <td>2026-02-17 05:13:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>313936975777235040</td>\n",
       "      <td>61088.097015</td>\n",
       "      <td>0.935171</td>\n",
       "      <td>42</td>\n",
       "      <td>52.509732</td>\n",
       "      <td>-28.277980</td>\n",
       "      <td>0.646</td>\n",
       "      <td>2026-02-17 05:13:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          diaObjectId  lastDiaSourceMjdTai   latestR  nDiaSources          ra  \\\n",
       "0  313963356964782123         61069.082988  0.977299            2   52.822487   \n",
       "1  313871013231722745         61088.212444  0.936848           23  149.156940   \n",
       "2  313936975777235040         61088.097015  0.935171           42   52.509732   \n",
       "\n",
       "        decl  separationArcsec                  UTC  \n",
       "0 -27.574832             1.599                  NaN  \n",
       "1   0.772347             0.326  2026-02-17 05:13:10  \n",
       "2 -28.277980             0.646  2026-02-17 05:13:10  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd44e96",
   "metadata": {},
   "source": [
    "As you can see the columns we have here are the same listed in our SQL query for the [Lasair Tutorial Basic Stream Filter](https://lasair-lsst-dev.lsst.ac.uk/filters/130/).\n",
    "\n",
    "**WARNING: UPDATE LINK**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "When creating your filter you can select from a few types of streams:\n",
    "* Kafka stream: Just the fields you selected during Filter creation\n",
    "* Lite lightcurve: The fields you selected at filter creation + the lightcurve history \n",
    "* Full Alert: The fields you selected + the full alert packet. \n",
    "\n",
    "In the example above we've only looked at the most basic form of output. \n",
    "Now we are going to play with the lightcurve and full alert modes.\n",
    "\n",
    "\n",
    "[Docs Reference: Alert Streams](https://lasair-lsst.readthedocs.io/en/main/core_functions/alert-streams.html#alert-streams)\n",
    "\n",
    "<h2 align=\"center\"> 5. Lite Lightcurve Alerts [NOT YET AVAILABLE]</h2>\n",
    "\n",
    "To get the lite Ligthcruev data we have to **Change our Topic to point to the right filter**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4ff023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"lasair_83lasair_tutorial_lite_lightcurve\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2b5e54",
   "metadata": {},
   "source": [
    "We also need to recreate our consumer to point to the right topic (note that changing the `group_id` here is unnecessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e47397d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = lasair_consumer(\n",
    "    kafka_server,    \n",
    "    group_id,        \n",
    "    topic            \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10606409",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "first = True\n",
    "# To ensure we don't leave out file open we work within a `with` scope\n",
    "with open(OUTPUT_PATH / f\"message_LiteLC.tmp.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    # first we write the opening square bracket for the json list\n",
    "    f.write(\"[\\n\")\n",
    "    while n < N:\n",
    "        msg = consumer.poll(timeout=20)\n",
    "        if msg is None:\n",
    "            break\n",
    "        if msg.error():\n",
    "            raise LasairError(\"Error while consuming message: {}\".format(msg.error()))\n",
    "            break\n",
    "        # 2. If we make it here it means we have messages. \n",
    "        raw = msg.value()\n",
    "        # msg.value() may be bytes or str depending on client\n",
    "        if isinstance(raw, bytes):\n",
    "            raw = raw.decode(\"utf-8\")\n",
    "\n",
    "        # 3. Get the JSON data for our alert.\n",
    "        result = json.loads(raw)\n",
    "        \n",
    "        # write comma before each object after the first\n",
    "        if not first:\n",
    "            f.write(\",\\n\")\n",
    "        first = False\n",
    "        \n",
    "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "        n += 1\n",
    "    f.write(\"]\\n\")\n",
    "\n",
    "os.replace(str(OUTPUT_PATH / f\"message_LiteLC.tmp.json\"), str(OUTPUT_PATH / f\"message_LiteLC.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afb13e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_llc = pd.read_json(OUTPUT_PATH/\"message_LiteLC.json\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c844ca03",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> 6. Full Alert Packet Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28c59ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%5|1771432401.898|REQTMOUT|rdkafka#consumer-4| [thrd:GroupCoordinator]: GroupCoordinator/1001: Timed out HeartbeatRequest in flight (after 45047ms, timeout #0)\n",
      "%4|1771432401.898|REQTMOUT|rdkafka#consumer-4| [thrd:GroupCoordinator]: GroupCoordinator/1001: Timed out 1 in-flight, 0 retry-queued, 0 out-queue, 0 partially-sent requests\n",
      "%5|1771432461.969|REQTMOUT|rdkafka#consumer-4| [thrd:lasair-lsst-dev-kafka_pub.lsst.ac.uk:9092/1001]: lasair-lsst-dev-kafka_pub.lsst.ac.uk:9092/1001: Timed out FindCoordinatorRequest in flight (after 60069ms, timeout #0)\n",
      "%4|1771432461.969|REQTMOUT|rdkafka#consumer-4| [thrd:lasair-lsst-dev-kafka_pub.lsst.ac.uk:9092/1001]: lasair-lsst-dev-kafka_pub.lsst.ac.uk:9092/1001: Timed out 1 in-flight, 0 retry-queued, 0 out-queue, 0 partially-sent requests\n",
      "%5|1771489464.953|REQTMOUT|rdkafka#consumer-4| [thrd:GroupCoordinator]: GroupCoordinator/1001: Timed out HeartbeatRequest in flight (after 45041ms, timeout #0)\n",
      "%4|1771489464.953|REQTMOUT|rdkafka#consumer-4| [thrd:GroupCoordinator]: GroupCoordinator/1001: Timed out 1 in-flight, 0 retry-queued, 0 out-queue, 0 partially-sent requests\n",
      "%5|1771489514.007|REQTMOUT|rdkafka#consumer-4| [thrd:lasair-lsst-dev-kafka_pub.lsst.ac.uk:9092/1001]: lasair-lsst-dev-kafka_pub.lsst.ac.uk:9092/1001: Timed out MetadataRequest in flight (after 60364ms, timeout #0)\n",
      "%4|1771489514.007|REQTMOUT|rdkafka#consumer-4| [thrd:lasair-lsst-dev-kafka_pub.lsst.ac.uk:9092/1001]: lasair-lsst-dev-kafka_pub.lsst.ac.uk:9092/1001: Timed out 1 in-flight, 0 retry-queued, 0 out-queue, 0 partially-sent requests\n"
     ]
    }
   ],
   "source": [
    "topic = \"lasair_83lvra_feeder_full\"\n",
    "consumer = lasair_consumer(\n",
    "    kafka_server,    \n",
    "    group_id,        \n",
    "    topic            \n",
    ")\n",
    "N = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec36bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "first = True\n",
    "# To ensure we don't leave out file open we work within a `with` scope\n",
    "with open(OUTPUT_PATH / f\"message_LiteLC.tmp.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    # first we write the opening square bracket for the json list\n",
    "    f.write(\"[\\n\")\n",
    "    while n < N:\n",
    "        msg = consumer.poll(timeout=20)\n",
    "        if msg is None:\n",
    "            break\n",
    "        if msg.error():\n",
    "            raise LasairError(\"Error while consuming message: {}\".format(msg.error()))\n",
    "            break\n",
    "        # 2. If we make it here it means we have messages. \n",
    "        raw = msg.value()\n",
    "        # msg.value() may be bytes or str depending on client\n",
    "        if isinstance(raw, bytes):\n",
    "            raw = raw.decode(\"utf-8\")\n",
    "\n",
    "        # 3. Get the JSON data for our alert.\n",
    "        result = json.loads(raw)\n",
    "        \n",
    "        # write comma before each object after the first\n",
    "        if not first:\n",
    "            f.write(\",\\n\")\n",
    "        first = False\n",
    "        \n",
    "        json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "        n += 1\n",
    "    f.write(\"]\\n\")\n",
    "\n",
    "os.replace(str(OUTPUT_PATH / f\"message_LiteLC.tmp.json\"), str(OUTPUT_PATH / f\"message_LiteLC.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744506e8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
